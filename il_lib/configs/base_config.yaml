defaults:
  - _self_  # all below configs will override this conf.yaml
  - policy: ???
  - task: ???

run_name: "${policy_name}_${task.name}"
exp_root_dir: .
policy_name: ???  # filled by policy
headless: true

# ====== Main Config ======
seed: 42
gpus: 1
num_nodes: 1
lr: 7e-4
use_cosine_lr: true
lr_warmup_steps: 1000
lr_cosine_steps: 300000
lr_cosine_min: 5e-6
lr_layer_decay: 1.0
wd: 0.0
bs: 64
vbs: ${bs}
data_dir: ???
eval_interval: 5
online_eval: true

horizon: ???
num_latest_obs: ???
deployed_action_steps: ???

# ====== Action Keys ======
action_keys: ["base", "torso", "left_arm", "left_gripper", "right_arm", "right_gripper"]
action_key_dims:
  base: 3
  torso: 4
  left_arm: 7
  left_gripper: 1
  right_arm: 7
  right_gripper: 1

# ====== Wandb ======
use_wandb: true
wandb_project: B1K
wandb_group: ${policy_name}
wandb_run_name: ${run_name}
progress_bar_refresh_rate: 100

# ====== Policy Module ======
module:
  _target_: ???  # filled by policy
  eval:
    ckpt: null  # path to the checkpoint to load for evaluation
    online_eval: ${online_eval}
    write_video: true
    headless: ${headless}
    env: ${env}
    task: ${task}
    robot: ${robot}
    policy_name: ${policy_name}
    model:
      _target_: omnigibson.learning.policies.VisionActionILPolicy
      use_websocket: false
      deployed_action_steps: ${deployed_action_steps}
      obs_window_size: ${num_latest_obs}
      obs_output_size: 
        left_wrist: [120, 120]
        right_wrist: [120, 120]
        head: [180, 180]
      visual_obs_types: ["rgb"]
      pcd_range: ${task.pcd_range}
  # ====== learning ======
  lr: ${lr}
  use_cosine_lr: ${use_cosine_lr}
  lr_warmup_steps: ${lr_warmup_steps}
  lr_cosine_steps: ${lr_cosine_steps}
  lr_cosine_min: ${lr_cosine_min}
  lr_layer_decay: ${lr_layer_decay}
  weight_decay: ${wd}
  action_keys: ${action_keys}

# ====== Data Module ======
data_module:
  _target_: il_lib.datas.BehaviorDataModule
  data_path: ${data_dir}
  task_name: ${task.name}
  batch_size: ${bs}
  val_batch_size: ${vbs}
  val_split_ratio: 0.1
  dataloader_num_workers: 4
  max_num_demos: null 
  seed: ${seed}
  # ====== Dataset ======
  obs_window_size: ${num_latest_obs}
  ctx_len: ${horizon}
  load_task_info: false
  multi_view_cameras:
    left_wrist: 
      name: robot_r1::robot_r1:left_realsense_link:Camera:0
      resolution: [120, 120]
    right_wrist: 
      name: robot_r1::robot_r1:right_realsense_link:Camera:0
      resolution: [120, 120]
    head: 
      name: robot_r1::robot_r1:zed_link:Camera:0
      resolution: [180, 180]

# ====== Trainer ======
trainer:
  accelerator: "gpu"
  devices: ${gpus}
  num_nodes: ${num_nodes}
  precision: 32
  strategy: ddp
  benchmark: true  # enables cudnn.benchmark
  accumulate_grad_batches: 1
  num_sanity_val_steps: 1
  max_epochs: 999999999
  val_check_interval: null
  check_val_every_n_epoch: ${eval_interval}
  gradient_clip_val: 1.0
  fast_dev_run: false
  checkpoint:  # this sub-dict will be popped to send to ModelCheckpoint as args
  - filename: "epoch{epoch}-train_loss{train/loss:.5f}"
    save_on_train_epoch_end: true  # this is a training metric, so we save it at the end of training epoch
    save_top_k: 10
    save_last: true
    monitor: "train/loss"
    mode: min
    auto_insert_metric_name: false  # prevent creating subfolder caused by the slash
  - filename: "epoch{epoch}-val_l1_{val/l1:.5f}"
    save_top_k: -1
    save_last: true
    monitor: "val/l1"
    mode: min
    auto_insert_metric_name: false  # prevent creating subfolder caused by the slash
  callbacks:
    - _target_: pytorch_lightning.callbacks.LearningRateMonitor
      logging_interval: step
    - _target_: pytorch_lightning.callbacks.RichModelSummary
    - _target_: il_lib.training.trainer.CustomProgressBar
      refresh_rate: ${progress_bar_refresh_rate}


# ====== Resume training ======
resume:
  ckpt_path: null
  full_state: false  # if true, resume all states including optimizer, amp, lightning callbacks
  strict: true
