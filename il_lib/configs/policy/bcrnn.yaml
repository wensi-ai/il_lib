# @package _global_

policy_name: bcrnn

# ====== Policy specific ======
horizon: 2
num_latest_obs: ${horizon}
deployed_action_steps: 1  # always deploy 1 action at a time
resnet_pretrained_ckpt_path: ???

# ------ module ------
module:
  _target_: il_lib.policies.BC_RNN
  eval:
    model:
      obs_window_size: 1  # At run time, we only use the latest observation
      visual_obs_types: ["rgb", "depth_linear"]
  prop_dim: 23
  prop_keys: ["odom/base_velocity", "qpos/torso", "qpos/left_arm", "qpos/left_gripper", "qpos/right_arm", "qpos/right_gripper"]
  # ====== Feature Extractors ======
  feature_extractors:
    proprioception:
      _target_: il_lib.nn.common.MLP
      input_dim: ${module.prop_dim}
      hidden_dim: 512
      output_dim: 512
      hidden_depth: 2
      add_output_activation: true
    rgb:
      _target_: il_lib.nn.features.MultiviewResNet18
      views: 
      - robot_r1::robot_r1:left_realsense_link:Camera:0::rgb
      - robot_r1::robot_r1:right_realsense_link:Camera:0::rgb
      - robot_r1::robot_r1:zed_link:Camera:0::rgb
      resnet_output_dim: 512
      token_dim: 512
      load_pretrained: true
      pretrained_ckpt_path: ${resnet_pretrained_ckpt_path}
      enable_random_crop: true
      random_crop_size: 94
  # ====== Feature Fusion ======
  feature_fusion_hidden_depth: 2
  feature_fusion_hidden_dim: 512
  feature_fusion_output_dim: 512
  feature_fusion_activation: "relu"
  feature_fusion_add_input_activation: false
  feature_fusion_add_output_activation: true
  rnn_n_layers: 2
  rnn_hidden_dim: 512
  rnn_horizon: ${horizon}
  # ====== Action ======
  action_dim: 23
  action_net_gmm_n_modes: 5
  action_net_hidden_dim: 128
  action_net_hidden_depth: 3
  action_net_activation: relu
  deterministic_inference: true
  gmm_low_noise_eval: true
  optimizer: "adam"

data_module:
  use_action_chunks: false
  visual_obs_types: ["rgb", "depth_linear"]
